# Spar and PySpark Inter View Question & Answer

### 1. What is spark? Explain Architecture
### 2. Explain where did you use spark in your project?
### 3. What all optimization techniques have you used in spark?
### 4. Explain transformations and actions have you used?
### 5. What happens when you use shuffle in spark?
### 6. Difference between ReduceByKey Vs GroupByKey?
### 7. Explain the issues you resolved when you working with spark?
### 8. Compare Spark vs Hadoop MapReduce?
### 9. Difference between Narrow & wide transformations?
### 10. What is partition and how spark Partitions the data?
### 11. What is RDD?
### 11. what is broadcast variable?
### 12. Difference between Sparkcontext Vs Sparksession?
### 13. Explain about transformations and actions in the spark?
### 14. what is Executor memory in spark?
### 15. What is lineage graph?
### 16. What is DAG?
### 17. Explain libraries that Spark Ecosystem supports?
### 18. What is a DStream?
### 19. What is Catalyst optimizer and explain it?
### 20. Why parquet file format is best for spark?
### 21. Difference between dataframe Vs Dataset Vs RDD?
### 22. Explain features of Apache Spark?
### 23. Explain Lazy evaluation and why is it need?
### 24. Explain Pair RDD?
### 25. What is Spark Core?
### 26. What is the difference between persist() and cache()?
### 27. What are the various levels of persistence in Apache Spark?
### 28. Does Apache Spark provide check pointing?
### 29. How can you achieve high availability in Apache Spark?
### 30. Explain Executor Memory in a Spark?
### 31. What are the disadvantages of using Apache Spark?
### 32. What is the default level of parallelism in apache spark?
### 33. Compare map() and flatMap() in Spark?
### 34. Difference between repartition Vs coalesce?
### 35. Explain Spark Streaming?
### 36. Explain accumulators?
### 37. What is the use of broadcast join?